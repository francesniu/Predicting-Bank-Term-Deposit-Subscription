{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Bank's Term Deposit Subscription - XGBoost Classification Model\n",
    "\n",
    "#### Author: Guansu(Frances) Niu\n",
    "\n",
    "#### Data Resource: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data:\n",
    "\n",
    "raw_data = pd.read_csv(\"data/raw data.csv\",sep=';')\n",
    "preprocessed_data = pd.read_csv(\"data/preprocessed data.csv\")\n",
    "\n",
    "pp_data = preprocessed_data.drop(preprocessed_data.columns[0], axis=1)\n",
    "\n",
    "X = pp_data.drop(['y'], inplace = False, axis = 1)\n",
    "y = pp_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202432155099011\n"
     ]
    }
   ],
   "source": [
    "# Calculate baseline of F1 score:\n",
    "\n",
    "# Method reference: \n",
    "# https://stats.stackexchange.com/questions/390200/what-is-the-baseline-of-the-f1-score-for-a-binary-classifier\n",
    "\n",
    "pp_data['y'].value_counts()\n",
    "count_0 = 36531\n",
    "prob_0 = count_0/len(pp_data['y'])\n",
    "prob_1 = (len(pp_data['y']) - count_0)/len(pp_data['y'])\n",
    "baseline = (2*prob_1)/(prob_1+1)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=56,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost: max_depth=11,f1_score=0.3927536231884058\n"
     ]
    }
   ],
   "source": [
    "# Tune parameters and get best F1 score:\n",
    "\n",
    "max_depths = range(7,14) \n",
    "f1_xgb=[]\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    xgb = XGBClassifier(max_depth=max_depth,learning_rate=0.1,random_state=458)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    f1_xgb.append(fbeta_score(y_test, y_pred_xgb,1))\n",
    "    \n",
    "best_max_depth = max_depths[np.argmax(f1_xgb)]\n",
    "\n",
    "print(f\"xgboost: max_depth={best_max_depth},f1_score={max(f1_xgb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37904190273634375\n"
     ]
    }
   ],
   "source": [
    "# Cross validation using parameters tuned from the best f1 score:\n",
    "\n",
    "xgb = XGBClassifier(max_depth=11, learning_rate=0.1,random_state=123)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=1)\n",
    "CV = (cross_val_score(xgb, X_train, y_train, cv=kf, n_jobs=1, scoring = 'f1').mean())\n",
    "print(CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007599212627488509\n"
     ]
    }
   ],
   "source": [
    "# Uncertainty due to splitting:\n",
    "\n",
    "uncertainty_split_xgb = []\n",
    "\n",
    "for i in range(1, 12, 2): \n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=i,stratify=y)\n",
    "\n",
    "    # Run the model using the tuned parameters:\n",
    "    xgb = XGBClassifier(max_depth=11,learning_rate=0.001,random_state=123)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "    # Cross validation\n",
    "    CV = (cross_val_score(xgb, X_train, y_train, cv=kf, n_jobs=1, scoring = 'f1').mean())\n",
    "    uncertainty_split_xgb.append(CV)\n",
    "print(np.std(uncertainty_split_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Uncertainty due to non-deterministic ML methods:\n",
    "\n",
    "uncertainty_ndeter_xgb = []\n",
    "\n",
    "for i in range(123, 500, 80): \n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=58,stratify=y)\n",
    "\n",
    "    # Run the model using the tuned parameters:\n",
    "    xgb = XGBClassifier(max_depth=11,learning_rate=0.001,random_state=i)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "    # Cross validation\n",
    "    CV = (cross_val_score(xgb, X_train, y_train, cv=kf, n_jobs=1, scoring = 'f1').mean())\n",
    "    uncertainty_ndeter_xgb.append(CV)\n",
    "print(np.std(uncertainty_ndeter_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7167,  140],\n",
       "       [ 690,  237]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix:\n",
    "\n",
    "confusion_matrix(y_test,y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8982268642215205"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score:\n",
    "\n",
    "accuracy_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8873855272426944\n"
     ]
    }
   ],
   "source": [
    "# Baseline of accuracy score:\n",
    "\n",
    "baseline_accuracy = np.array(pp_data[\"y\"].value_counts()/pp_data.shape[0])[0]\n",
    "print(baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For xgboost classification:\n",
    "\n",
    "The F1 score is 0.379 (after cross validation) with tuned parameters max_depth = 11.\n",
    "\n",
    "The uncertainties due to splitting is 0.00760, and due to non-deterministic ML method is 0.0.\n",
    "\n",
    "The accuracy score is 0.898."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
