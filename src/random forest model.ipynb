{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Bank's Term Deposit Subscription - Random Forest Classification Model\n",
    "\n",
    "#### Author: Guansu(Frances) Niu\n",
    "\n",
    "#### Data Resource: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data:\n",
    "\n",
    "pp_data = pd.read_csv(\"data/preprocessed data.csv\")\n",
    "label = 'y'\n",
    "y = LabelEncoder().fit_transform(df[label])\n",
    "df.drop(columns=[label],inplace=True)\n",
    "X = df\n",
    "ftr_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202432155099011\n"
     ]
    }
   ],
   "source": [
    "# Calculate baseline of F1 score:\n",
    "\n",
    "# Method reference: \n",
    "# https://stats.stackexchange.com/questions/390200/what-is-the-baseline-of-the-f1-score-for-a-binary-classifier\n",
    "\n",
    "pp_data['y'].value_counts()\n",
    "count_0 = 36531\n",
    "prob_0 = count_0/len(pp_data['y'])\n",
    "prob_1 = (len(pp_data['y']) - count_0)/len(pp_data['y'])\n",
    "baseline = (2*prob_1)/(prob_1+1)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state =random_state,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing:\n",
    "\n",
    "cat_ftrs = ['job', 'marital', 'default', 'housing','loan', 'contact','poutcome']\n",
    "\n",
    "ordinal_ftrs = ['education','month','day_of_week']\n",
    "\n",
    "ordinal_cats = [['basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', \n",
    "                'university.degree','missing'],['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep','oct',\n",
    "                'nov','dec'],['mon', 'tue', 'wed', 'thu', 'fri']]\n",
    "\n",
    "num_ftrs = ['age','campaign','previous','emp.var.rate','cons.price.idx','cons.conf.idx', \n",
    "                 'euribor3m','nr.employed']\n",
    "\n",
    "# one-hot encoder\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "\n",
    "# ordinal encoder\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer2', SimpleImputer(strategy='constant',fill_value='NA')),\n",
    "    ('ordinal', OrdinalEncoder(categories = ordinal_cats))])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('ord', ordinal_transformer, ordinal_ftrs)])\n",
    "\n",
    "# fit_transform the training set\n",
    "X_prep = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Collect feature names\n",
    "\n",
    "feature_names = preprocessor.transformers_[0][-1] + \\\n",
    "                list(preprocessor.named_transformers_['cat'][1].get_feature_names(cat_ftrs)) + \\\n",
    "                preprocessor.transformers_[2][-1]\n",
    "\n",
    "X_train = pd.DataFrame(data=X_prep,columns=feature_names)\n",
    "\n",
    "# transform the test\n",
    "df_test = preprocessor.transform(X_test)\n",
    "X_test = pd.DataFrame(data=df_test,columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest: max_feature=15,max_depth=9,f1_score=0.3745261561789234\n"
     ]
    }
   ],
   "source": [
    "# Tune parameters and get best F1 score:\n",
    "\n",
    "max_features = range(10,20) \n",
    "max_depths = range(5,10) \n",
    "f1_rfc={\"max_feature\":[],\"max_depth\":[],\"f1_score\":[]}\n",
    "\n",
    "for max_feature in max_features:\n",
    "    for max_depth in max_depths:\n",
    "        rfc = RandomForestClassifier(n_estimators=100,\n",
    "                                     max_depth=max_depth,max_features=max_feature,\n",
    "                                     random_state=random_state)\n",
    "        rfc.fit(X_train, y_train)\n",
    "        y_pred_rfc = rfc.predict(X_test)\n",
    "        f1_rfc['f1_score'].append(fbeta_score(y_test, y_pred_rfc,1))\n",
    "        f1_rfc['max_depth'].append(max_depth)\n",
    "        f1_rfc['max_feature'].append(max_feature)\n",
    "max_f1_rfc = max(f1_rfc['f1_score'])\n",
    "best_max_feature = f1_rfc['max_feature'][np.argmax(f1_rfc['f1_score'])]\n",
    "best_max_depth = f1_rfc['max_depth'][np.argmax(f1_rfc['f1_score'])]\n",
    "print(f\"random forest: max_feature={best_max_feature},max_depth={best_max_depth},\\\n",
    "f1_score={max_f1_rfc}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3666976070940632\n"
     ]
    }
   ],
   "source": [
    "# Cross validation using parameters tuned from the best f1 score:\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100,max_depth=9,max_features=15,random_state=random_state)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=1)\n",
    "CV = (cross_val_score(rfc, X_train, y_train, cv=kf, n_jobs=1, scoring = 'f1').mean())\n",
    "print(CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00499765587448889\n"
     ]
    }
   ],
   "source": [
    "# Uncertainty due to splitting:\n",
    "\n",
    "uncertainty_split_rfc = []\n",
    "\n",
    "for i in range(1, 12, 2): \n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=i,stratify=y)\n",
    "\n",
    "    # Run the model using the tuned parameters:\n",
    "    rfc = RandomForestClassifier(n_estimators=100,max_depth=8,max_features=16,random_state=123)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "    # Cross validation\n",
    "    CV = (cross_val_score(rfc, X_train, y_train, cv=kf, n_jobs=1, scoring = 'f1').mean())\n",
    "    uncertainty_split_rfc.append(CV)\n",
    "print(np.std(uncertainty_split_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018626119520612472\n"
     ]
    }
   ],
   "source": [
    "# Uncertainty due to non-deterministic ML methods:\n",
    "\n",
    "uncertainty_ndeter_rfc = []\n",
    "\n",
    "for i in range(123, 500, 80): \n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1,stratify=y)\n",
    "\n",
    "    # Run the model using the tuned parameters:\n",
    "    rfc = RandomForestClassifier(n_estimators=100,max_depth=9,max_features=18,random_state=i)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "    # Cross validation\n",
    "    CV = (cross_val_score(rfc, X_train, y_train, cv=kf, n_jobs=1, scoring = 'f1').mean())\n",
    "    uncertainty_ndeter_rfc.append(CV)\n",
    "print(np.std(uncertainty_ndeter_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7162,  145],\n",
       "       [ 680,  247]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix:\n",
    "\n",
    "confusion_matrix(y_test, y_pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8998056837503036"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score:\n",
    "\n",
    "accuracy_score(y_test, y_pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8873855272426944\n"
     ]
    }
   ],
   "source": [
    "# Baseline of accuracy score:\n",
    "\n",
    "baseline_accuracy = np.array(pp_data[\"y\"].value_counts()/pp_data.shape[0])[0]\n",
    "print(baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For random forest classification:\n",
    "\n",
    "The F1 score is 0.367 (after cross validation) with tuned parameters max_feature = 16 and max_depth = 8.\n",
    "\n",
    "The uncertainties due to splitting is 0.00450, and due to non-deterministic ML method is 0.00186.\n",
    "\n",
    "The accuracy score is 0.90."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
