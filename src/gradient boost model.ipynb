{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Bank's Term Deposit Subscription - Gradient Boost Classification Model\n",
    "\n",
    "#### Author: Guansu(Frances) Niu\n",
    "\n",
    "#### Data Resource: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data:\n",
    "\n",
    "raw_data = pd.read_csv(\"data/raw data.csv\",sep=';')\n",
    "preprocessed_data = pd.read_csv(\"data/preprocessed data.csv\")\n",
    "\n",
    "pp_data = preprocessed_data.drop(preprocessed_data.columns[0], axis=1)\n",
    "\n",
    "X = pp_data.drop(['y'], inplace = False, axis = 1)\n",
    "y = pp_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202432155099011\n"
     ]
    }
   ],
   "source": [
    "# Calculate baseline of F1 score:\n",
    "\n",
    "# Method reference: \n",
    "# https://stats.stackexchange.com/questions/390200/what-is-the-baseline-of-the-f1-score-for-a-binary-classifier\n",
    "\n",
    "pp_data['y'].value_counts()\n",
    "count_0 = 36531\n",
    "prob_0 = count_0/len(pp_data['y'])\n",
    "prob_1 = (len(pp_data['y']) - count_0)/len(pp_data['y'])\n",
    "baseline = (2*prob_1)/(prob_1+1)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state =467,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient boost: max_depth=11,f1_score=0.38634812286689424\n"
     ]
    }
   ],
   "source": [
    "# Tune parameters and get best F1 score:\n",
    "\n",
    "max_depths = range(10,14) \n",
    "f1_gbc=[]\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    gbc = GradientBoostingClassifier(max_depth=max_depth,n_estimators=100,random_state=123)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    y_pred_gbc = gbc.predict(X_test)\n",
    "    f1_gbc.append(fbeta_score(y_test,y_pred_gbc,1))\n",
    "    \n",
    "best_max_depth = max_depths[np.argmax(f1_gbc)]\n",
    "\n",
    "print(f\"gradient boost: max_depth={best_max_depth},f1_score={max(f1_gbc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39125514578358356\n"
     ]
    }
   ],
   "source": [
    "# Cross validation using parameters tuned from the best f1 score:\n",
    "\n",
    "gbc = GradientBoostingClassifier(max_depth=11,n_estimators=100,random_state=123)\n",
    "gbc.fit(X_train, y_train)\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=1)\n",
    "CV = (cross_val_score(gbc, X_train, y_train, cv=kf, n_jobs=1, scoring = 'f1').mean())\n",
    "print(CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006919718421499724\n"
     ]
    }
   ],
   "source": [
    "# Uncertainty due to splitting:\n",
    "\n",
    "uncertainty_split_gbc = []\n",
    "\n",
    "for i in range(1, 12, 2): \n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=i,stratify=y)\n",
    "\n",
    "    # Run the model using the tuned parameters:\n",
    "    gbc = GradientBoostingClassifier(max_depth=5,n_estimators=500,random_state=123)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "    # Cross validation\n",
    "    CV = (cross_val_score(gbc, X_train, y_train, cv=kf, n_jobs=1, scoring = 'f1').mean())\n",
    "    uncertainty_split_gbc.append(CV)\n",
    "print(np.std(uncertainty_split_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008558466612630979\n"
     ]
    }
   ],
   "source": [
    "# Uncertainty due to non-deterministic ML methods:\n",
    "\n",
    "uncertainty_ndeter_gbc = []\n",
    "\n",
    "for i in range(123, 700, 80): \n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=58,stratify=y)\n",
    "\n",
    "    # Run the model using the tuned parameters:\n",
    "    gbc = GradientBoostingClassifier(max_depth=5,n_estimators=500,random_state=i)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "    # Cross validation\n",
    "    CV = (cross_val_score(gbc, X_train, y_train, cv=kf, n_jobs=1, scoring = 'f1').mean())\n",
    "    uncertainty_ndeter_gbc.append(CV)\n",
    "print(np.std(uncertainty_ndeter_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6884,  423],\n",
       "       [ 881,   46]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix:\n",
    "\n",
    "confusion_matrix(y_test,y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416322564974495"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score:\n",
    "\n",
    "accuracy_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8873855272426944\n"
     ]
    }
   ],
   "source": [
    "# Baseline of accuracy score:\n",
    "\n",
    "baseline_accuracy = np.array(pp_data[\"y\"].value_counts()/pp_data.shape[0])[0]\n",
    "print(baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For gradient boost classification:\n",
    "\n",
    "The F1 score is 0.391 (after cross validation) with tuned parameters max_depth = 11.\n",
    "\n",
    "The uncertainties due to splitting is 0.00692, and due to non-deterministic ML method is 0.000856.\n",
    "\n",
    "The accuracy score is 0.842."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
